{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Automated Data Quality Checks Implementation\n",
    "\n",
    "## Objectives\n",
    "1. Implement automated data quality checks\n",
    "2. Set up validation rules for HR data\n",
    "3. Create reporting mechanism for data quality issues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import logging\n",
    "\n",
    "# Setup logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load HR data files\n",
    "def load_hr_data():\n",
    "    data_files = {\n",
    "        'people': '../../dummy_data/PER_ALL_PEOPLE_F_20241216.csv',\n",
    "        'assignments': '../../dummy_data/PER_ALL_ASSIGNMENTS_F_20241216.csv',\n",
    "        'addresses': '../../dummy_data/HR_ALL_ADDRESSES_20241216.csv'\n",
    "    }\n",
    "    \n",
    "    return {name: pd.read_csv(path) for name, path in data_files.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HRDataValidator:\n",
    "    def __init__(self):\n",
    "        self.logger = logging.getLogger(__name__)\n",
    "        \n",
    "    def validate_date_format(self, date_str):\n",
    "        \"\"\"Validate if a string is in the correct date format (YYYY-MM-DD)\"\"\"\n",
    "        try:\n",
    "            datetime.strptime(date_str, '%Y-%m-%d')\n",
    "            return True\n",
    "        except ValueError:\n",
    "            return False\n",
    "            \n",
    "    def check_missing_values(self, df, threshold=0.1):\n",
    "        \"\"\"Check for columns with missing values above threshold\"\"\"\n",
    "        missing_stats = df.isnull().sum() / len(df)\n",
    "        return missing_stats[missing_stats > threshold]\n",
    "        \n",
    "    def check_duplicates(self, df, subset=None):\n",
    "        \"\"\"Check for duplicate records\"\"\"\n",
    "        return df.duplicated(subset=subset).sum()\n",
    "        \n",
    "    def validate_numeric_range(self, series, min_val, max_val):\n",
    "        \"\"\"Validate if numeric values are within expected range\"\"\"\n",
    "        return series.between(min_val, max_val)\n",
    "    \n",
    "    def validate_email_format(self, series):\n",
    "        \"\"\"Validate email format using basic pattern matching\"\"\"\n",
    "        return series.str.match(r'^[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,}$')\n",
    "    \n",
    "    def validate_nino_format(self, series):\n",
    "        \"\"\"Validate National Insurance Number format\"\"\"\n",
    "        return series.str.match(r'^[A-CEGHJ-PR-TW-Z][A-CEGHJ-NPR-TW-Z][0-9]{6}[A-D]$')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HRDataQualityPipeline:\n",
    "    def __init__(self):\n",
    "        self.validator = HRDataValidator()\n",
    "        self.logger = logging.getLogger(__name__)\n",
    "        \n",
    "    def run_quality_checks(self, data):\n",
    "        \"\"\"Run all quality checks on the HR data\"\"\"\n",
    "        results = {}\n",
    "        \n",
    "        for dataset_name, df in data.items():\n",
    "            self.logger.info(f\"Running quality checks for {dataset_name}\")\n",
    "            results[dataset_name] = {\n",
    "                'missing_values': self.validator.check_missing_values(df),\n",
    "                'duplicates': self.validator.check_duplicates(df)\n",
    "            }\n",
    "            \n",
    "            # Specific checks for people dataset\n",
    "            if dataset_name == 'people':\n",
    "                if 'email' in df.columns:\n",
    "                    results[dataset_name]['invalid_emails'] = ~self.validator.validate_email_format(df['email'])\n",
    "                if 'nino' in df.columns:\n",
    "                    results[dataset_name]['invalid_ninos'] = ~self.validator.validate_nino_format(df['nino'])\n",
    "                    \n",
    "            # Specific checks for dates\n",
    "            date_columns = df.select_dtypes(include=['object']).columns\n",
    "            for col in date_columns:\n",
    "                if 'date' in col.lower():\n",
    "                    results[dataset_name][f'invalid_dates_{col}'] = df[col].apply(\n",
    "                        lambda x: not self.validator.validate_date_format(str(x)) if pd.notna(x) else False\n",
    "                    )\n",
    "        \n",
    "        return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QualityReportGenerator:\n",
    "    def __init__(self):\n",
    "        self.logger = logging.getLogger(__name__)\n",
    "        \n",
    "    def generate_summary(self, quality_results):\n",
    "        \"\"\"Generate a summary report of data quality issues\"\"\"\n",
    "        summary = []\n",
    "        \n",
    "        for dataset_name, results in quality_results.items():\n",
    "            summary.append(f\"\\nQuality Report for {dataset_name}:\")\n",
    "            summary.append(\"-\" * 50)\n",
    "            \n",
    "            # Missing values\n",
    "            missing = results['missing_values']\n",
    "            if not missing.empty:\n",
    "                summary.append(\"\\nColumns with high missing values:\")\n",
    "                for col, pct in missing.items():\n",
    "                    summary.append(f\"  - {col}: {pct:.2%} missing\")\n",
    "            \n",
    "            # Duplicates\n",
    "            dupes = results['duplicates']\n",
    "            if dupes > 0:\n",
    "                summary.append(f\"\\nDuplicate records found: {dupes}\")\n",
    "            \n",
    "            # Invalid emails\n",
    "            if 'invalid_emails' in results:\n",
    "                invalid_count = results['invalid_emails'].sum()\n",
    "                if invalid_count > 0:\n",
    "                    summary.append(f\"\\nInvalid email formats: {invalid_count}\")\n",
    "            \n",
    "            # Invalid NINOs\n",
    "            if 'invalid_ninos' in results:\n",
    "                invalid_count = results['invalid_ninos'].sum()\n",
    "                if invalid_count > 0:\n",
    "                    summary.append(f\"\\nInvalid NINO formats: {invalid_count}\")\n",
    "            \n",
    "            # Invalid dates\n",
    "            date_issues = {k: v for k, v in results.items() if k.startswith('invalid_dates_')}\n",
    "            if date_issues:\n",
    "                summary.append(\"\\nInvalid date formats:\")\n",
    "                for col, invalid_mask in date_issues.items():\n",
    "                    col_name = col.replace('invalid_dates_', '')\n",
    "                    invalid_count = invalid_mask.sum()\n",
    "                    if invalid_count > 0:\n",
    "                        summary.append(f\"  - {col_name}: {invalid_count} invalid dates\")\n",
    "        \n",
    "        return '\\n'.join(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-17 14:28:37,145 - INFO - Running quality checks for people\n",
      "2024-12-17 14:28:37,158 - INFO - Running quality checks for assignments\n",
      "2024-12-17 14:28:37,168 - INFO - Running quality checks for addresses\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Quality Report for people:\n",
      "--------------------------------------------------\n",
      "\n",
      "Invalid NINO formats: 989\n",
      "\n",
      "Invalid date formats:\n",
      "\n",
      "Quality Report for assignments:\n",
      "--------------------------------------------------\n",
      "\n",
      "Invalid date formats:\n",
      "\n",
      "Quality Report for addresses:\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    # Initialize components\n",
    "    pipeline = HRDataQualityPipeline()\n",
    "    report_generator = QualityReportGenerator()\n",
    "    \n",
    "    try:\n",
    "        # Load data\n",
    "        hr_data = load_hr_data()\n",
    "        \n",
    "        # Run quality checks\n",
    "        quality_results = pipeline.run_quality_checks(hr_data)\n",
    "        \n",
    "        # Generate and display report\n",
    "        report = report_generator.generate_summary(quality_results)\n",
    "        print(report)\n",
    "        \n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error in data quality pipeline: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
